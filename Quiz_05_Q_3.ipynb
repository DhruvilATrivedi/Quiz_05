{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Quiz_05_Q_3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "O84a9blX59ly"
      },
      "source": [
        "#Importing libraries\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import tensorflow"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNxiZ65i6Mts"
      },
      "source": [
        "#Importing MNIST dataset from tensorflow keras\r\n",
        "(trainval_x, trainval_y), (test_x, test_y) = tensorflow.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "TV2ARBph6aGS",
        "outputId": "08f115cb-f9e1-4a03-e549-f5e21e005781"
      },
      "source": [
        "#Plotting certain images from the dataset\r\n",
        "fig, axes = plt.subplots(1, 3, figsize = (12, 4))\r\n",
        "axes[0].imshow(trainval_x[9])\r\n",
        "axes[1].imshow(trainval_x[16])\r\n",
        "axes[2].imshow(trainval_x[27])\r\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUBlLhb_7rpO",
        "outputId": "eadf9701-e066-4847-ee5d-32198d7fcd84"
      },
      "source": [
        "#Converting the data from utf-8 format to float format\r\n",
        "trainval_x = np.float32(trainval_x)\r\n",
        "trainval_x"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vT5fiQb-_FZR",
        "outputId": "bea6005a-16e2-40b5-fd76-5921eee42e83"
      },
      "source": [
        "#Converting the test data from utf-8 format to float format\r\n",
        "test_x = np.float32(test_x)\r\n",
        "test_x"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Om8D-mwJGCTk",
        "outputId": "982d46d0-a806-40b0-8bfb-a7ee7bf434cd"
      },
      "source": [
        "#Creating a validation set from the train dataset\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "train_x, val_x, train_y, val_y = train_test_split(trainval_x, trainval_y, test_size = 0.2, random_state = 42)\r\n",
        "train_x.shape, val_x.shape, test_x.shape, train_y.shape, val_y.shape, test_y.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((48000, 28, 28),\n",
              " (12000, 28, 28),\n",
              " (10000, 28, 28),\n",
              " (48000,),\n",
              " (12000,),\n",
              " (10000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnUYWVvSGCQN"
      },
      "source": [
        "#Creating a neural network model with 2 dense layers\r\n",
        "nn_model = tensorflow.keras.Sequential([\r\n",
        "    tensorflow.keras.layers.Flatten(input_shape = (28,28)),\r\n",
        "    tensorflow.keras.layers.Dense(32, activation='relu'),\r\n",
        "    tensorflow.keras.layers.Dense(64, activation='relu'),\r\n",
        "    tensorflow.keras.layers.Dense(10)\r\n",
        "])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OlEsL7RGCNo",
        "outputId": "16f519ef-f93f-43ae-8e48-7051f4e792e3"
      },
      "source": [
        "#Compiling the model\r\n",
        "nn_model.compile(optimizer='adam', loss = tensorflow.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics='accuracy')\r\n",
        "nn_model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 27,882\n",
            "Trainable params: 27,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivutvKmzJknV",
        "outputId": "bd339e28-0786-4cd2-dc99-cd162f827d48"
      },
      "source": [
        "#Fitting the model over the data and storing the loss and accuracy values\r\n",
        "history = nn_model.fit(train_x, train_y, epochs=100, validation_data=(val_x, val_y))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 4.8046 - accuracy: 0.5842 - val_loss: 0.5582 - val_accuracy: 0.8622\n",
            "Epoch 2/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.4954 - accuracy: 0.8737 - val_loss: 0.4469 - val_accuracy: 0.8902\n",
            "Epoch 3/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4113 - accuracy: 0.8974 - val_loss: 0.3733 - val_accuracy: 0.9141\n",
            "Epoch 4/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3703 - accuracy: 0.9115 - val_loss: 0.4111 - val_accuracy: 0.9025\n",
            "Epoch 5/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3343 - accuracy: 0.9160 - val_loss: 0.3637 - val_accuracy: 0.9121\n",
            "Epoch 6/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3252 - accuracy: 0.9167 - val_loss: 0.3452 - val_accuracy: 0.9153\n",
            "Epoch 7/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2976 - accuracy: 0.9221 - val_loss: 0.3436 - val_accuracy: 0.9134\n",
            "Epoch 8/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2606 - accuracy: 0.9290 - val_loss: 0.3206 - val_accuracy: 0.9216\n",
            "Epoch 9/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2415 - accuracy: 0.9317 - val_loss: 0.2742 - val_accuracy: 0.9302\n",
            "Epoch 10/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2253 - accuracy: 0.9350 - val_loss: 0.3019 - val_accuracy: 0.9259\n",
            "Epoch 11/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2256 - accuracy: 0.9363 - val_loss: 0.2714 - val_accuracy: 0.9285\n",
            "Epoch 12/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2065 - accuracy: 0.9412 - val_loss: 0.2645 - val_accuracy: 0.9312\n",
            "Epoch 13/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2032 - accuracy: 0.9429 - val_loss: 0.2517 - val_accuracy: 0.9317\n",
            "Epoch 14/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1919 - accuracy: 0.9445 - val_loss: 0.2707 - val_accuracy: 0.9312\n",
            "Epoch 15/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1808 - accuracy: 0.9462 - val_loss: 0.2484 - val_accuracy: 0.9323\n",
            "Epoch 16/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1853 - accuracy: 0.9465 - val_loss: 0.2247 - val_accuracy: 0.9383\n",
            "Epoch 17/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1725 - accuracy: 0.9494 - val_loss: 0.2389 - val_accuracy: 0.9352\n",
            "Epoch 18/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1696 - accuracy: 0.9507 - val_loss: 0.2328 - val_accuracy: 0.9380\n",
            "Epoch 19/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1646 - accuracy: 0.9534 - val_loss: 0.2323 - val_accuracy: 0.9383\n",
            "Epoch 20/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1625 - accuracy: 0.9529 - val_loss: 0.2386 - val_accuracy: 0.9336\n",
            "Epoch 21/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1622 - accuracy: 0.9515 - val_loss: 0.2356 - val_accuracy: 0.9373\n",
            "Epoch 22/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1623 - accuracy: 0.9532 - val_loss: 0.2428 - val_accuracy: 0.9362\n",
            "Epoch 23/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1621 - accuracy: 0.9530 - val_loss: 0.2288 - val_accuracy: 0.9375\n",
            "Epoch 24/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1544 - accuracy: 0.9578 - val_loss: 0.2158 - val_accuracy: 0.9433\n",
            "Epoch 25/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1500 - accuracy: 0.9575 - val_loss: 0.2335 - val_accuracy: 0.9379\n",
            "Epoch 26/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1516 - accuracy: 0.9574 - val_loss: 0.2262 - val_accuracy: 0.9422\n",
            "Epoch 27/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1430 - accuracy: 0.9585 - val_loss: 0.2257 - val_accuracy: 0.9392\n",
            "Epoch 28/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1364 - accuracy: 0.9596 - val_loss: 0.2098 - val_accuracy: 0.9438\n",
            "Epoch 29/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1371 - accuracy: 0.9606 - val_loss: 0.2180 - val_accuracy: 0.9409\n",
            "Epoch 30/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1333 - accuracy: 0.9615 - val_loss: 0.2163 - val_accuracy: 0.9429\n",
            "Epoch 31/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1380 - accuracy: 0.9611 - val_loss: 0.2280 - val_accuracy: 0.9446\n",
            "Epoch 32/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1316 - accuracy: 0.9628 - val_loss: 0.2295 - val_accuracy: 0.9417\n",
            "Epoch 33/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1309 - accuracy: 0.9611 - val_loss: 0.2034 - val_accuracy: 0.9491\n",
            "Epoch 34/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1187 - accuracy: 0.9660 - val_loss: 0.2164 - val_accuracy: 0.9451\n",
            "Epoch 35/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1202 - accuracy: 0.9660 - val_loss: 0.2232 - val_accuracy: 0.9425\n",
            "Epoch 36/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1261 - accuracy: 0.9645 - val_loss: 0.2332 - val_accuracy: 0.9463\n",
            "Epoch 37/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1261 - accuracy: 0.9637 - val_loss: 0.2510 - val_accuracy: 0.9403\n",
            "Epoch 38/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1193 - accuracy: 0.9660 - val_loss: 0.2306 - val_accuracy: 0.9482\n",
            "Epoch 39/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1197 - accuracy: 0.9654 - val_loss: 0.2395 - val_accuracy: 0.9425\n",
            "Epoch 40/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1157 - accuracy: 0.9664 - val_loss: 0.2454 - val_accuracy: 0.9441\n",
            "Epoch 41/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1144 - accuracy: 0.9664 - val_loss: 0.2370 - val_accuracy: 0.9429\n",
            "Epoch 42/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1210 - accuracy: 0.9666 - val_loss: 0.2705 - val_accuracy: 0.9452\n",
            "Epoch 43/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1156 - accuracy: 0.9677 - val_loss: 0.2397 - val_accuracy: 0.9455\n",
            "Epoch 44/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1114 - accuracy: 0.9681 - val_loss: 0.2605 - val_accuracy: 0.9457\n",
            "Epoch 45/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1114 - accuracy: 0.9689 - val_loss: 0.2490 - val_accuracy: 0.9447\n",
            "Epoch 46/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1120 - accuracy: 0.9678 - val_loss: 0.2484 - val_accuracy: 0.9449\n",
            "Epoch 47/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1165 - accuracy: 0.9661 - val_loss: 0.2593 - val_accuracy: 0.9473\n",
            "Epoch 48/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1131 - accuracy: 0.9680 - val_loss: 0.2698 - val_accuracy: 0.9440\n",
            "Epoch 49/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1091 - accuracy: 0.9689 - val_loss: 0.2539 - val_accuracy: 0.9496\n",
            "Epoch 50/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1037 - accuracy: 0.9706 - val_loss: 0.2390 - val_accuracy: 0.9484\n",
            "Epoch 51/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1066 - accuracy: 0.9702 - val_loss: 0.2525 - val_accuracy: 0.9472\n",
            "Epoch 52/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1069 - accuracy: 0.9707 - val_loss: 0.2734 - val_accuracy: 0.9449\n",
            "Epoch 53/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1088 - accuracy: 0.9695 - val_loss: 0.2506 - val_accuracy: 0.9438\n",
            "Epoch 54/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1087 - accuracy: 0.9690 - val_loss: 0.2486 - val_accuracy: 0.9482\n",
            "Epoch 55/100\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1098 - accuracy: 0.9690 - val_loss: 0.2769 - val_accuracy: 0.9448\n",
            "Epoch 56/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1051 - accuracy: 0.9704 - val_loss: 0.2763 - val_accuracy: 0.9426\n",
            "Epoch 57/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1073 - accuracy: 0.9696 - val_loss: 0.2713 - val_accuracy: 0.9475\n",
            "Epoch 58/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1035 - accuracy: 0.9700 - val_loss: 0.2764 - val_accuracy: 0.9449\n",
            "Epoch 59/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1035 - accuracy: 0.9717 - val_loss: 0.2766 - val_accuracy: 0.9444\n",
            "Epoch 60/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1029 - accuracy: 0.9708 - val_loss: 0.2665 - val_accuracy: 0.9463\n",
            "Epoch 61/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0982 - accuracy: 0.9715 - val_loss: 0.3006 - val_accuracy: 0.9440\n",
            "Epoch 62/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0993 - accuracy: 0.9716 - val_loss: 0.2709 - val_accuracy: 0.9484\n",
            "Epoch 63/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1010 - accuracy: 0.9711 - val_loss: 0.3127 - val_accuracy: 0.9468\n",
            "Epoch 64/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1010 - accuracy: 0.9723 - val_loss: 0.2700 - val_accuracy: 0.9456\n",
            "Epoch 65/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0969 - accuracy: 0.9719 - val_loss: 0.2741 - val_accuracy: 0.9488\n",
            "Epoch 66/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0971 - accuracy: 0.9723 - val_loss: 0.3282 - val_accuracy: 0.9442\n",
            "Epoch 67/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0975 - accuracy: 0.9728 - val_loss: 0.2855 - val_accuracy: 0.9485\n",
            "Epoch 68/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0983 - accuracy: 0.9725 - val_loss: 0.3229 - val_accuracy: 0.9449\n",
            "Epoch 69/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1035 - accuracy: 0.9717 - val_loss: 0.3132 - val_accuracy: 0.9483\n",
            "Epoch 70/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0947 - accuracy: 0.9727 - val_loss: 0.3978 - val_accuracy: 0.9467\n",
            "Epoch 71/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0965 - accuracy: 0.9728 - val_loss: 0.3309 - val_accuracy: 0.9477\n",
            "Epoch 72/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0921 - accuracy: 0.9735 - val_loss: 0.3483 - val_accuracy: 0.9427\n",
            "Epoch 73/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1029 - accuracy: 0.9713 - val_loss: 0.3819 - val_accuracy: 0.9414\n",
            "Epoch 74/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0940 - accuracy: 0.9738 - val_loss: 0.3827 - val_accuracy: 0.9432\n",
            "Epoch 75/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1066 - accuracy: 0.9705 - val_loss: 0.3851 - val_accuracy: 0.9468\n",
            "Epoch 76/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0980 - accuracy: 0.9721 - val_loss: 0.3576 - val_accuracy: 0.9440\n",
            "Epoch 77/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1051 - accuracy: 0.9707 - val_loss: 0.3524 - val_accuracy: 0.9462\n",
            "Epoch 78/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0960 - accuracy: 0.9723 - val_loss: 0.3930 - val_accuracy: 0.9462\n",
            "Epoch 79/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1005 - accuracy: 0.9718 - val_loss: 0.3174 - val_accuracy: 0.9475\n",
            "Epoch 80/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0987 - accuracy: 0.9721 - val_loss: 0.3235 - val_accuracy: 0.9468\n",
            "Epoch 81/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0876 - accuracy: 0.9746 - val_loss: 0.3638 - val_accuracy: 0.9441\n",
            "Epoch 82/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0968 - accuracy: 0.9734 - val_loss: 0.3769 - val_accuracy: 0.9421\n",
            "Epoch 83/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0884 - accuracy: 0.9740 - val_loss: 0.3769 - val_accuracy: 0.9433\n",
            "Epoch 84/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1052 - accuracy: 0.9720 - val_loss: 0.3796 - val_accuracy: 0.9426\n",
            "Epoch 85/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1074 - accuracy: 0.9710 - val_loss: 0.3833 - val_accuracy: 0.9432\n",
            "Epoch 86/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0900 - accuracy: 0.9745 - val_loss: 0.3638 - val_accuracy: 0.9421\n",
            "Epoch 87/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0960 - accuracy: 0.9722 - val_loss: 0.4194 - val_accuracy: 0.9433\n",
            "Epoch 88/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0884 - accuracy: 0.9734 - val_loss: 0.4099 - val_accuracy: 0.9437\n",
            "Epoch 89/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0871 - accuracy: 0.9755 - val_loss: 0.3751 - val_accuracy: 0.9462\n",
            "Epoch 90/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0880 - accuracy: 0.9753 - val_loss: 0.3963 - val_accuracy: 0.9409\n",
            "Epoch 91/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1007 - accuracy: 0.9718 - val_loss: 0.3742 - val_accuracy: 0.9462\n",
            "Epoch 92/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0927 - accuracy: 0.9734 - val_loss: 0.3587 - val_accuracy: 0.9400\n",
            "Epoch 93/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0944 - accuracy: 0.9729 - val_loss: 0.3939 - val_accuracy: 0.9472\n",
            "Epoch 94/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0899 - accuracy: 0.9739 - val_loss: 0.3727 - val_accuracy: 0.9446\n",
            "Epoch 95/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0871 - accuracy: 0.9757 - val_loss: 0.4553 - val_accuracy: 0.9435\n",
            "Epoch 96/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1077 - accuracy: 0.9710 - val_loss: 0.3708 - val_accuracy: 0.9434\n",
            "Epoch 97/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0854 - accuracy: 0.9765 - val_loss: 0.4114 - val_accuracy: 0.9435\n",
            "Epoch 98/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0941 - accuracy: 0.9739 - val_loss: 0.3845 - val_accuracy: 0.9456\n",
            "Epoch 99/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0884 - accuracy: 0.9743 - val_loss: 0.4957 - val_accuracy: 0.9446\n",
            "Epoch 100/100\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0994 - accuracy: 0.9722 - val_loss: 0.4378 - val_accuracy: 0.9439\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvq7t09fLLyl",
        "outputId": "32b105ad-9520-48db-d615-117f91f77536"
      },
      "source": [
        "#Printing the values loss and accuracy values of train and validation dataset\r\n",
        "history.history"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.7246458530426025,\n",
              "  0.879562497138977,\n",
              "  0.8976874947547913,\n",
              "  0.9079166650772095,\n",
              "  0.9138333201408386,\n",
              "  0.9176041483879089,\n",
              "  0.9222916960716248,\n",
              "  0.9272708296775818,\n",
              "  0.929604172706604,\n",
              "  0.934374988079071,\n",
              "  0.9371041655540466,\n",
              "  0.9401458501815796,\n",
              "  0.9427083134651184,\n",
              "  0.9436666369438171,\n",
              "  0.944979190826416,\n",
              "  0.9457291960716248,\n",
              "  0.9473333358764648,\n",
              "  0.9496874809265137,\n",
              "  0.949916660785675,\n",
              "  0.9516666531562805,\n",
              "  0.9512708187103271,\n",
              "  0.9519791603088379,\n",
              "  0.953083336353302,\n",
              "  0.9555416703224182,\n",
              "  0.9564999938011169,\n",
              "  0.9571666717529297,\n",
              "  0.9571666717529297,\n",
              "  0.9592916369438171,\n",
              "  0.9593333601951599,\n",
              "  0.960812509059906,\n",
              "  0.9607083201408386,\n",
              "  0.9622708559036255,\n",
              "  0.9617916941642761,\n",
              "  0.9628541469573975,\n",
              "  0.963895857334137,\n",
              "  0.9634583592414856,\n",
              "  0.9631249904632568,\n",
              "  0.9647499918937683,\n",
              "  0.9649999737739563,\n",
              "  0.9659583568572998,\n",
              "  0.9650833606719971,\n",
              "  0.9649166464805603,\n",
              "  0.9665833115577698,\n",
              "  0.9664999842643738,\n",
              "  0.9666249752044678,\n",
              "  0.9667708277702332,\n",
              "  0.9661874771118164,\n",
              "  0.9675624966621399,\n",
              "  0.9673541784286499,\n",
              "  0.9679166674613953,\n",
              "  0.9689375162124634,\n",
              "  0.9691666960716248,\n",
              "  0.969083309173584,\n",
              "  0.9678750038146973,\n",
              "  0.9685624837875366,\n",
              "  0.9691874980926514,\n",
              "  0.968833327293396,\n",
              "  0.96895831823349,\n",
              "  0.968999981880188,\n",
              "  0.9693541526794434,\n",
              "  0.9708124995231628,\n",
              "  0.9699583053588867,\n",
              "  0.9698333144187927,\n",
              "  0.9697499871253967,\n",
              "  0.9721875190734863,\n",
              "  0.9712499976158142,\n",
              "  0.9716249704360962,\n",
              "  0.9707083106040955,\n",
              "  0.9709374904632568,\n",
              "  0.9719791412353516,\n",
              "  0.9707083106040955,\n",
              "  0.9714791774749756,\n",
              "  0.9707291722297668,\n",
              "  0.9731458425521851,\n",
              "  0.9713958501815796,\n",
              "  0.9718541502952576,\n",
              "  0.9709374904632568,\n",
              "  0.9718124866485596,\n",
              "  0.9719374775886536,\n",
              "  0.9724375009536743,\n",
              "  0.9724166393280029,\n",
              "  0.9721875190734863,\n",
              "  0.973479151725769,\n",
              "  0.9711458086967468,\n",
              "  0.971916675567627,\n",
              "  0.9739999771118164,\n",
              "  0.9731875061988831,\n",
              "  0.972000002861023,\n",
              "  0.9729375243186951,\n",
              "  0.9739999771118164,\n",
              "  0.9726874828338623,\n",
              "  0.9731041789054871,\n",
              "  0.9724166393280029,\n",
              "  0.9729999899864197,\n",
              "  0.9746458530426025,\n",
              "  0.9730416536331177,\n",
              "  0.9756041765213013,\n",
              "  0.9730833172798157,\n",
              "  0.9742708206176758,\n",
              "  0.9722916483879089],\n",
              " 'loss': [1.604046106338501,\n",
              "  0.4789682626724243,\n",
              "  0.41141295433044434,\n",
              "  0.37694257497787476,\n",
              "  0.34332141280174255,\n",
              "  0.3177819550037384,\n",
              "  0.299251526594162,\n",
              "  0.26830825209617615,\n",
              "  0.25389590859413147,\n",
              "  0.23448748886585236,\n",
              "  0.22536100447177887,\n",
              "  0.21266166865825653,\n",
              "  0.20309893786907196,\n",
              "  0.1968846172094345,\n",
              "  0.1874406486749649,\n",
              "  0.18645280599594116,\n",
              "  0.18029995262622833,\n",
              "  0.17707394063472748,\n",
              "  0.1737300157546997,\n",
              "  0.1656274050474167,\n",
              "  0.1658783107995987,\n",
              "  0.16631117463111877,\n",
              "  0.16488699615001678,\n",
              "  0.1577562391757965,\n",
              "  0.1521192491054535,\n",
              "  0.1510331779718399,\n",
              "  0.14871922135353088,\n",
              "  0.14135432243347168,\n",
              "  0.14064498245716095,\n",
              "  0.13832703232765198,\n",
              "  0.13640199601650238,\n",
              "  0.1323859691619873,\n",
              "  0.13240917026996613,\n",
              "  0.13010895252227783,\n",
              "  0.12914982438087463,\n",
              "  0.129375159740448,\n",
              "  0.1268128901720047,\n",
              "  0.12160352617502213,\n",
              "  0.12459096312522888,\n",
              "  0.11909016966819763,\n",
              "  0.12078963220119476,\n",
              "  0.12507246434688568,\n",
              "  0.11982434242963791,\n",
              "  0.11583985388278961,\n",
              "  0.11874333024024963,\n",
              "  0.11708970367908478,\n",
              "  0.11823699623346329,\n",
              "  0.11522029340267181,\n",
              "  0.11386334896087646,\n",
              "  0.11639944463968277,\n",
              "  0.1106162741780281,\n",
              "  0.11230025440454483,\n",
              "  0.11038809269666672,\n",
              "  0.11418482661247253,\n",
              "  0.10994809120893478,\n",
              "  0.10922271758317947,\n",
              "  0.1101321205496788,\n",
              "  0.11166967451572418,\n",
              "  0.10871006548404694,\n",
              "  0.10904542356729507,\n",
              "  0.10243269056081772,\n",
              "  0.10460993647575378,\n",
              "  0.10709032416343689,\n",
              "  0.11230538040399551,\n",
              "  0.10068629682064056,\n",
              "  0.10295141488313675,\n",
              "  0.10115666687488556,\n",
              "  0.1040203869342804,\n",
              "  0.10426009446382523,\n",
              "  0.09970557689666748,\n",
              "  0.1008564680814743,\n",
              "  0.09948120266199112,\n",
              "  0.10708192735910416,\n",
              "  0.09592252969741821,\n",
              "  0.10266952216625214,\n",
              "  0.09926533699035645,\n",
              "  0.10312400013208389,\n",
              "  0.09934155642986298,\n",
              "  0.1034054160118103,\n",
              "  0.09647364169359207,\n",
              "  0.09567776322364807,\n",
              "  0.0995558351278305,\n",
              "  0.09339756518602371,\n",
              "  0.10701879858970642,\n",
              "  0.10287635028362274,\n",
              "  0.09408427774906158,\n",
              "  0.0959453135728836,\n",
              "  0.09711604565382004,\n",
              "  0.09616060554981232,\n",
              "  0.09187547117471695,\n",
              "  0.09582361578941345,\n",
              "  0.09856955707073212,\n",
              "  0.09739180654287338,\n",
              "  0.09572375565767288,\n",
              "  0.09015948325395584,\n",
              "  0.10382339358329773,\n",
              "  0.08822061866521835,\n",
              "  0.09987116605043411,\n",
              "  0.08964508026838303,\n",
              "  0.09806521236896515],\n",
              " 'val_accuracy': [0.8621666431427002,\n",
              "  0.8901666402816772,\n",
              "  0.9140833616256714,\n",
              "  0.9024999737739563,\n",
              "  0.9120833277702332,\n",
              "  0.9152500033378601,\n",
              "  0.9134166836738586,\n",
              "  0.921583354473114,\n",
              "  0.9302499890327454,\n",
              "  0.9259166717529297,\n",
              "  0.9284999966621399,\n",
              "  0.9311666488647461,\n",
              "  0.9316666722297668,\n",
              "  0.9311666488647461,\n",
              "  0.9323333501815796,\n",
              "  0.9382500052452087,\n",
              "  0.9351666569709778,\n",
              "  0.9380000233650208,\n",
              "  0.9382500052452087,\n",
              "  0.9335833191871643,\n",
              "  0.937250018119812,\n",
              "  0.9362499713897705,\n",
              "  0.9375,\n",
              "  0.9432500004768372,\n",
              "  0.9379166960716248,\n",
              "  0.9421666860580444,\n",
              "  0.9391666650772095,\n",
              "  0.9437500238418579,\n",
              "  0.9409166574478149,\n",
              "  0.9429166913032532,\n",
              "  0.9445833563804626,\n",
              "  0.9416666626930237,\n",
              "  0.9490833282470703,\n",
              "  0.9450833201408386,\n",
              "  0.9424999952316284,\n",
              "  0.9463333487510681,\n",
              "  0.9403333067893982,\n",
              "  0.9482499957084656,\n",
              "  0.9424999952316284,\n",
              "  0.9440833330154419,\n",
              "  0.9429166913032532,\n",
              "  0.9451666474342346,\n",
              "  0.9455000162124634,\n",
              "  0.9457499980926514,\n",
              "  0.9446666836738586,\n",
              "  0.9449166655540466,\n",
              "  0.9472500085830688,\n",
              "  0.9440000057220459,\n",
              "  0.9495833516120911,\n",
              "  0.9484166502952576,\n",
              "  0.9471666812896729,\n",
              "  0.9449166655540466,\n",
              "  0.9438333511352539,\n",
              "  0.9482499957084656,\n",
              "  0.9448333382606506,\n",
              "  0.9425833225250244,\n",
              "  0.9474999904632568,\n",
              "  0.9449166655540466,\n",
              "  0.9444166421890259,\n",
              "  0.9463333487510681,\n",
              "  0.9440000057220459,\n",
              "  0.9484166502952576,\n",
              "  0.9468333125114441,\n",
              "  0.9455833435058594,\n",
              "  0.9488333463668823,\n",
              "  0.9442499876022339,\n",
              "  0.9484999775886536,\n",
              "  0.9449166655540466,\n",
              "  0.9483333230018616,\n",
              "  0.9466666579246521,\n",
              "  0.9477499723434448,\n",
              "  0.9426666498184204,\n",
              "  0.9414166808128357,\n",
              "  0.9431666731834412,\n",
              "  0.9468333125114441,\n",
              "  0.9440000057220459,\n",
              "  0.9461666941642761,\n",
              "  0.9461666941642761,\n",
              "  0.9474999904632568,\n",
              "  0.9468333125114441,\n",
              "  0.9440833330154419,\n",
              "  0.9420833587646484,\n",
              "  0.9432500004768372,\n",
              "  0.9425833225250244,\n",
              "  0.9431666731834412,\n",
              "  0.9420833587646484,\n",
              "  0.9433333277702332,\n",
              "  0.9436666369438171,\n",
              "  0.9461666941642761,\n",
              "  0.9409166574478149,\n",
              "  0.9461666941642761,\n",
              "  0.9399999976158142,\n",
              "  0.9471666812896729,\n",
              "  0.9445833563804626,\n",
              "  0.9434999823570251,\n",
              "  0.9434166550636292,\n",
              "  0.9434999823570251,\n",
              "  0.9455833435058594,\n",
              "  0.9445833563804626,\n",
              "  0.9439166784286499],\n",
              " 'val_loss': [0.5581613779067993,\n",
              "  0.4468748867511749,\n",
              "  0.3733132779598236,\n",
              "  0.41110143065452576,\n",
              "  0.3637142777442932,\n",
              "  0.3451577425003052,\n",
              "  0.3435640037059784,\n",
              "  0.32063230872154236,\n",
              "  0.2742137014865875,\n",
              "  0.30194491147994995,\n",
              "  0.27136051654815674,\n",
              "  0.26454153656959534,\n",
              "  0.25167563557624817,\n",
              "  0.2706926465034485,\n",
              "  0.24844560027122498,\n",
              "  0.22469362616539001,\n",
              "  0.23892687261104584,\n",
              "  0.23284699022769928,\n",
              "  0.23234251141548157,\n",
              "  0.2386358082294464,\n",
              "  0.23560167849063873,\n",
              "  0.24282926321029663,\n",
              "  0.2287963628768921,\n",
              "  0.21579131484031677,\n",
              "  0.23346519470214844,\n",
              "  0.2262142151594162,\n",
              "  0.22566041350364685,\n",
              "  0.209783673286438,\n",
              "  0.2180006355047226,\n",
              "  0.21627868711948395,\n",
              "  0.22803044319152832,\n",
              "  0.22954165935516357,\n",
              "  0.2034120261669159,\n",
              "  0.21638236939907074,\n",
              "  0.22319018840789795,\n",
              "  0.23323683440685272,\n",
              "  0.2509719729423523,\n",
              "  0.23056560754776,\n",
              "  0.23945613205432892,\n",
              "  0.24544352293014526,\n",
              "  0.23695261776447296,\n",
              "  0.2705002725124359,\n",
              "  0.2397230863571167,\n",
              "  0.260538786649704,\n",
              "  0.24898791313171387,\n",
              "  0.24835556745529175,\n",
              "  0.2592572569847107,\n",
              "  0.269802451133728,\n",
              "  0.25392404198646545,\n",
              "  0.23902453482151031,\n",
              "  0.25246408581733704,\n",
              "  0.27336686849594116,\n",
              "  0.25060129165649414,\n",
              "  0.24863967299461365,\n",
              "  0.2768622040748596,\n",
              "  0.2763124704360962,\n",
              "  0.27129220962524414,\n",
              "  0.2764473557472229,\n",
              "  0.2766073942184448,\n",
              "  0.26654866337776184,\n",
              "  0.3006129264831543,\n",
              "  0.2709256708621979,\n",
              "  0.3126579821109772,\n",
              "  0.27003830671310425,\n",
              "  0.2741152048110962,\n",
              "  0.3281514644622803,\n",
              "  0.28547292947769165,\n",
              "  0.3229236304759979,\n",
              "  0.31319525837898254,\n",
              "  0.39777871966362,\n",
              "  0.3309212028980255,\n",
              "  0.34834447503089905,\n",
              "  0.3818502724170685,\n",
              "  0.38267070055007935,\n",
              "  0.385060578584671,\n",
              "  0.3576425313949585,\n",
              "  0.3524033725261688,\n",
              "  0.3929799497127533,\n",
              "  0.31735774874687195,\n",
              "  0.3234914541244507,\n",
              "  0.36383455991744995,\n",
              "  0.3769276440143585,\n",
              "  0.37693750858306885,\n",
              "  0.3795766234397888,\n",
              "  0.38328662514686584,\n",
              "  0.3638383448123932,\n",
              "  0.4194161891937256,\n",
              "  0.4099205732345581,\n",
              "  0.37505266070365906,\n",
              "  0.3962571620941162,\n",
              "  0.37415361404418945,\n",
              "  0.3586799204349518,\n",
              "  0.3939017057418823,\n",
              "  0.3727499544620514,\n",
              "  0.45531728863716125,\n",
              "  0.3707702159881592,\n",
              "  0.41141316294670105,\n",
              "  0.3844836950302124,\n",
              "  0.49569448828697205,\n",
              "  0.43777287006378174]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFl3u9ndJkkN",
        "outputId": "313819f7-b48a-4d16-a5dd-66f65309787b"
      },
      "source": [
        "#Testing the actual model\r\n",
        "test_loss, test_accuracy = nn_model.evaluate(test_x, test_y, verbose=2)\r\n",
        "test_loss, test_accuracy"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 0s - loss: 0.4949 - accuracy: 0.9445\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4949353039264679, 0.9445000290870667)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "_2ZfNbiQJkhq",
        "outputId": "4fc82609-1d3a-4093-8ca2-eb8db55d94ae"
      },
      "source": [
        "#Plotting the graph for train loss and validation loss\r\n",
        "plt.plot(history.history['loss'], 'k-', label = 'Loss function for train dataset')\r\n",
        "plt.plot(history.history['val_loss'], 'r-', label = 'Loss function for validation dataset')\r\n",
        "plt.xlabel('Epochs')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmwoTNELQQIR"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    }
  ]
}